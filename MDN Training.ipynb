{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Density Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import h5py\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import genconfig\n",
    "from train_MDN import train_nn, mixture_density_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import yaml\n",
    "Option = namedtuple(\"MyStruct\", \"training_input training_output validation_fraction outFile network_type \\\n",
    "                    config structure learning_rate regularizer epochs batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Particle Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Config file, options are : 'number','pos1','pos2','pos3', 'error1x', 'error1y', 'error2x', 'error2y', 'error3x', 'error3y'  \n",
    "Below is example of pos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python genconfig.py --type pos1 > pos1config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with generated config run train_nn which stores training history in text file in training_output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loading config from:  pos2config.json\n"
    }
   ],
   "source": [
    "options = Option(\n",
    "    training_input='NNinput_pos2_training.h5',\n",
    "    training_output='Trained',\n",
    "    validation_fraction=0.1,\n",
    "    outFile='pos2',\n",
    "    network_type='2particle',\n",
    "    config='pos2config.json',\n",
    "    structure=[100, 80, 50],\n",
    "    learning_rate=0.0001,\n",
    "    regularizer=0.0001,\n",
    "    epochs=250,\n",
    "    batch=1000\n",
    ")\n",
    "\n",
    "print('loading config from: ', options.config)\n",
    "config = open(options.config, 'r')\n",
    "yamlConfig = yaml.load(config, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(['NN_matrix0', 'NN_matrix1', 'NN_matrix2', 'NN_matrix3', 'NN_matrix4', 'NN_matrix5', 'NN_matrix6', 'NN_matrix7', 'NN_matrix8', 'NN_matrix9', 'NN_matrix10', 'NN_matrix11', 'NN_matrix12', 'NN_matrix13', 'NN_matrix14', 'NN_matrix15', 'NN_matrix16', 'NN_matrix17', 'NN_matrix18', 'NN_matrix19', 'NN_matrix20', 'NN_matrix21', 'NN_matrix22', 'NN_matrix23', 'NN_matrix24', 'NN_matrix25', 'NN_matrix26', 'NN_matrix27', 'NN_matrix28', 'NN_matrix29', 'NN_matrix30', 'NN_matrix31', 'NN_matrix32', 'NN_matrix33', 'NN_matrix34', 'NN_matrix35', 'NN_matrix36', 'NN_matrix37', 'NN_matrix38', 'NN_matrix39', 'NN_matrix40', 'NN_matrix41', 'NN_matrix42', 'NN_matrix43', 'NN_matrix44', 'NN_matrix45', 'NN_matrix46', 'NN_matrix47', 'NN_matrix48', 'NN_pitches0', 'NN_pitches1', 'NN_pitches2', 'NN_pitches3', 'NN_pitches4', 'NN_pitches5', 'NN_pitches6', 'NN_layer', 'NN_barrelEC', 'NN_phi', 'NN_theta'], ['NN_position_id_X_0', 'NN_position_id_Y_0', 'NN_position_id_X_1', 'NN_position_id_Y_1'], [])\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'intdataSetSize' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-97a5e28bc2fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                         \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                         \u001b[1;31m#args.momentum,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                         \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                         \u001b[1;31m##args.min_epochs,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                         \u001b[1;31m#args.max_epochs,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\saran\\GitHub\\pixel-mdn-training-tensorflow-master\\train_MDN.py\u001b[0m in \u001b[0;36mtrain_nn\u001b[1;34m(training_input, training_output, validation_fraction, outFile, network_type, config, structure, learning_rate, regularizer, epochs, batch, patience, verbose)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0mtestDataSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainDataSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSetSize\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[0mtrainDataSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainDataSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintdataSetSize\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[0mtestDataSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestDataSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'intdataSetSize' is not defined"
     ]
    }
   ],
   "source": [
    "model_2, history_2 = train_nn(\n",
    "                        options.training_input,\n",
    "                        options.training_output,\n",
    "                        options.validation_fraction,\n",
    "                        options.outFile,\n",
    "                        options.network_type,\n",
    "                        options.config,\n",
    "                        options.structure,\n",
    "                        options.learning_rate,\n",
    "                        options.regularizer,\n",
    "                        options.epochs,\n",
    "                        #args.momentum,\n",
    "                        options.batch,\n",
    "                        ##args.min_epochs,\n",
    "                        #args.max_epochs,\n",
    "                        ##args.patience_increase,\n",
    "                        ##args.threshold,\n",
    "                        #args.min_delta,\n",
    "                        #args.patience,\n",
    "                        #args.profile,\n",
    "                        #args.nbworkers,\n",
    "                        #args.save_all,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output = 'Trained'\n",
    "outFile = 'pos2'\n",
    "output_location = training_output+'/'+outFile+'_'+datetime.datetime.now().strftime('%m_%d_%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_2.save(output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(output_location, custom_objects={'abs' : tf.keras.backend.abs,\n",
    "                                                                        'loss' : mixture_density_loss(nb_components=1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2.x features method model.save() which creates model file that stores both the weights and architecture. Loading the model from this format requires only custom objects like the above activation and loss functions to be provided. That means it includes the config, optimizer, and weights of the model. Older Tensorflow/keras model saving format required saving a weights .h5 file as well as the config and rebuilding the model and its architecture from that, which still requires the custom objects as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve Two Particle Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = np.loadtxt('Trained/pos2_06_04_0556_training_pos2.txt')\n",
    "validation_loss = np.loadtxt('Trained/pos2_06_04_0556_validation_pos2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(train_loss, val_loss, fileName, outputDir):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    \n",
    "    plt.plot(train_loss, color='b', linewidth=0.5)\n",
    "    plt.plot(val_loss, color='r', linewidth=0.5)\n",
    "    plt.title('Model Loss over Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.xlim(0,250)\n",
    "    plt.ylim(0, 0.9)\n",
    "    plt.legend(['training set','validation set'])\n",
    "    plt.savefig(outputDir+'/'+fileName+'_Loss.pdf')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(training_loss, validation_loss, 'pos2', 'Trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Particle Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python genconfig.py --type pos1 > pos1config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = Option(\n",
    "    training_input='NNinput_pos1_training.h5',\n",
    "    training_output='Trained',\n",
    "    validation_fraction=0.1,\n",
    "    outFile='pos1',\n",
    "    network_type='1particle',\n",
    "    config='pos1config.json',\n",
    "    structure=[100, 80, 50],\n",
    "    learning_rate=0.0001,\n",
    "    regularizer=0.0001,\n",
    "    epochs=250,\n",
    ")\n",
    "\n",
    "print('loading config from: ', options.config)\n",
    "config = open(options.config, 'r')\n",
    "yamlConfig = yaml.load(config, Loader=yaml.FullLoader)\n",
    "yamlConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_1, history_1 = train_nn(\n",
    "                        options.training_input,\n",
    "                        options.training_output,\n",
    "                        options.validation_fraction,\n",
    "                        options.outFile,\n",
    "                        options.network_type,\n",
    "                        options.config,\n",
    "                        options.structure,\n",
    "                        options.learning_rate,\n",
    "                        options.regularizer,\n",
    "                        options.epochs,\n",
    "                        #args.momentum,\n",
    "                        #args.batch,\n",
    "                        ##args.min_epochs,\n",
    "                        #args.max_epochs,\n",
    "                        ##args.patience_increase,\n",
    "                        ##args.threshold,\n",
    "                        #args.min_delta,\n",
    "                        #args.patience,\n",
    "                        #args.profile,\n",
    "                        #args.nbworkers,\n",
    "                        #args.save_all,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Particle Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python genconfig.py --type pos3 > pos3config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = Option(\n",
    "    training_input='NNinput_pos3_training.h5',\n",
    "    training_output='Trained',\n",
    "    validation_fraction=0.1,\n",
    "    outFile='pos3',\n",
    "    network_type='3particle',\n",
    "    config='pos3config.json',\n",
    "    structure=[100, 80, 50],\n",
    "    learning_rate=0.0001,\n",
    "    regularizer=0.0001,\n",
    "    epochs=250,\n",
    ")\n",
    "\n",
    "print('loading config from: ', options.config)\n",
    "config = open(options.config, 'r')\n",
    "yamlConfig = yaml.load(config, Loader=yaml.FullLoader)\n",
    "yamlConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_3, history_3 = train_nn(\n",
    "                        options.training_input,\n",
    "                        options.training_output,\n",
    "                        options.validation_fraction,\n",
    "                        options.outFile,\n",
    "                        options.network_type,\n",
    "                        options.config,\n",
    "                        options.structure,\n",
    "                        options.learning_rate,\n",
    "                        options.regularizer,\n",
    "                        options.epochs,\n",
    "                        #args.momentum,\n",
    "                        #args.batch,\n",
    "                        ##args.min_epochs,\n",
    "                        #args.max_epochs,\n",
    "                        ##args.patience_increase,\n",
    "                        ##args.threshold,\n",
    "                        #args.min_delta,\n",
    "                        #args.patience,\n",
    "                        #args.profile,\n",
    "                        #args.nbworkers,\n",
    "                        #args.save_all,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2p = tf.keras.models.load_model('Trained/pos2_06_04_0556', custom_objects={'abs' : tf.keras.backend.abs,\n",
    "                                                                        'loss' : mixture_density_loss(nb_components=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('NNinput_pos2_training.h5', 'r') as hf:  \n",
    "    #x_train = hf['train_data_x'][:]\n",
    "    #y_train = hf['train_data_y'][:]\n",
    "    x_valid = hf['valid_data_x'][:]\n",
    "    y_valid = hf['valid_data_y'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "branches = utils.get_data_config_names('pos2config.json', meta=False)\n",
    "print(branches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_2p.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean = np.hstack((y_pred[0][:,1:3], y_pred[1][:,1:3]))\n",
    "pred_mean[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prec = np.hstack((y_pred[0][:,3:5], y_pred[1][:,3:5]))\n",
    "pred_prec[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(y_pred[0][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1 = tf.reshape(x_valid[0], [1,60])\n",
    "x_test_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_1 = model_2p.predict(x_test_1)\n",
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('MDNtraining_TF': conda)",
   "language": "python",
   "name": "python361064bitmdntrainingtfconda41395b29b3f64ff7b5d12b9937ed94c7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}